{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Prerequisites: Upload the course_bachelors.yaml file to Google Drive in order to rerun the code"
      ],
      "metadata": {
        "id": "0luR8IkORvUc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLmkz-kFPmMQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers , activations , models , preprocessing , utils\n",
        "import pickle\n",
        "import re\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive in Colab\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIwJ4V0asim2",
        "outputId": "9699d0ab-34ec-4a89-d190-b3b49005c1d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VTkYUcYbjDbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "with open(r'/content/gdrive/MyDrive/course_bachelors.yaml') as file:\n",
        "  documents = yaml.load(file)\n",
        "documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKO4UEtpnLki",
        "outputId": "5eea95e3-bea5-475f-adfb-80f64e7e9cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'categories': ['course', \"Bachelor's\"],\n",
              " 'conversations': [['How long is the duration of the course?', 'Three years.'],\n",
              "  ['What are the entry requirements for the course?',\n",
              "   'Minimum entry requirements are a grade H5 and above in two higher level subjects together with a minimum of O6/H7 in four other subjects. A minimum of grade O6/H7 must be obtained in English. A grade O5/H6 must be obtained in Mathematics.For applicants whose first language is not English, please note the English language entry requirements. Mature applicants, applicants with a disability or those applying through the DARE or HEAR access schemes can find out more information on the application process.'],\n",
              "  ['How much is the tuition fees for the course?',\n",
              "   'The fees for this course for international students is €10000 per year. For domestic students applying through the CAO, this course applies under the free fees initiative.']]}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dp5QFeN-jD2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The dataset is split into question and answer lists. For our chatbot, we have used the conversations subject of the dataset.\n",
        "\n",
        "questions, answers = [], []\n",
        "\n",
        "conversations = documents['conversations']\n",
        "\n",
        "for conv in conversations:\n",
        "  if len(conv) > 2 :\n",
        "    questions.append(conv[0])\n",
        "    replies = conv[1 :]\n",
        "    ans = ' '\n",
        "    for rep in replies:\n",
        "      ans += ' ' + rep\n",
        "      answers.append(ans)\n",
        "  elif len(conv) > 1:\n",
        "    questions.append(conv[0])\n",
        "    answers.append(conv[1])"
      ],
      "metadata": {
        "id": "0LbtFVWEtyio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLf2Crt4vlUl",
        "outputId": "79f0666b-f16e-4401-bbcc-bbb5c71505fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['How long is the duration of the course?',\n",
              " 'What are the entry requirements for the course?',\n",
              " 'How much is the tuition fees for the course?']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItMtUiJwvuqg",
        "outputId": "9f9824a6-09fb-4bcd-8ca3-d132a7bbfaaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Three years.',\n",
              " 'Minimum entry requirements are a grade H5 and above in two higher level subjects together with a minimum of O6/H7 in four other subjects. A minimum of grade O6/H7 must be obtained in English. A grade O5/H6 must be obtained in Mathematics.For applicants whose first language is not English, please note the English language entry requirements. Mature applicants, applicants with a disability or those applying through the DARE or HEAR access schemes can find out more information on the application process.',\n",
              " 'The fees for this course for international students is €10000 per year. For domestic students applying through the CAO, this course applies under the free fees initiative.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing for seq2seq learning\n",
        "\n",
        "# For preprocessing, a single vocabulary is used for tokenization.\n",
        "\n",
        "answers_tags = []\n",
        "\n",
        "for i in range(len(answers)):\n",
        "  if type(answers[i]) == str:\n",
        "    answers_tags.append(answers[i])\n",
        "  else:\n",
        "    questions.pop(i)\n",
        "\n",
        "answers = []\n",
        "\n",
        "for i in range(len(answers_tags)):\n",
        "  answers.append('<START>' + answers_tags[i] + '<END>')\n",
        "\n",
        "tokenizer = preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(questions + answers)\n",
        "\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "XPwIPbfdv5Y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb7n4GM8mG07",
        "outputId": "e6b5fbee-39f3-465c-896e-cee51509ab49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = []\n",
        "\n",
        "for word in tokenizer.word_index:\n",
        "  vocab.append(word)\n",
        "\n",
        "def tokenize(sentences):\n",
        "  tokens_list = []\n",
        "  vocabulary = []\n",
        "  for sentence in sentences:\n",
        "    sentence = sentence.lower()\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "    tokens = sentence.split()\n",
        "    vocabulary += tokens\n",
        "    tokens_list.append(tokens)\n",
        "  return tokens_list, vocabulary"
      ],
      "metadata": {
        "id": "x3HpSXfJmJ12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder input data\n",
        "\n",
        "tokenized_questions = tokenizer.texts_to_sequences(questions)\n",
        "\n",
        "maxlen_questions = max([len(x) for x in tokenized_questions])\n",
        "\n",
        "encoder_input_data = preprocessing.sequence.pad_sequences(tokenized_questions, maxlen=maxlen_questions, padding='post')\n",
        "\n",
        "#padded_questions = preprocessing.sequence.pad_sequences(tokenized_questions, maxlen=maxlen_questions, padding='post')\n",
        "\n",
        "#encoder_input_data = np.array([padded_questions])\n",
        "\n",
        "print(encoder_input_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh8_iiQFnOop",
        "outputId": "e83ac3cf-c06e-45ff-b02f-d1a70758b0db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder input data\n",
        "\n",
        "tokenized_answers = tokenizer.texts_to_sequences(answers)\n",
        "\n",
        "maxlen_answers = max([len(x) for x in tokenized_answers])\n",
        "\n",
        "decoder_input_data = preprocessing.sequence.pad_sequences(tokenized_answers, maxlen=maxlen_answers, padding='post')\n",
        "\n",
        "#padded_answers = preprocessing.sequence.pad_sequences(tokenized_answers, maxlen=maxlen_answers, padding='post')\n",
        "\n",
        "#decoder_input_data = np.array(padded_answers)\n",
        "\n",
        "print(decoder_input_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnbZ5M8XpIOa",
        "outputId": "f1ae503b-af3d-49a7-b5f6-4b9eb1d3a467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 87)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder output data\n",
        "\n",
        "tokenized_answers = tokenizer.texts_to_sequences(answers)\n",
        "\n",
        "for i in range(len(tokenized_answers)):\n",
        "  tokenized_answers[i] = tokenized_answers[i][1:]\n",
        "\n",
        "padded_answers = preprocessing.sequence.pad_sequences(tokenized_answers, maxlen=maxlen_answers, padding='post')\n",
        "\n",
        "decoder_output_data = utils.to_categorical(padded_answers, VOCAB_SIZE)\n",
        "\n",
        "#onehot_answers = utils.to_categorical(padded_answers, VOCAB_SIZE)\n",
        "\n",
        "#decoder_output_data = np.array([onehot_answers])\n",
        "\n",
        "print(decoder_output_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7k5PnDGpc39",
        "outputId": "d3f9390e-5a24-47c2-c9d5-f13399fc59f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 87, 81)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the model\n",
        "# Keras Functional API is used to build the architecture of the model. \n",
        "# The model is a multi input model, the encoder input and the decoder input. \n",
        "# Successive layers include the Embedding and the LSTM layers\n",
        "\n",
        "# Embedding LSTM and Desne Layers\n",
        "\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(maxlen_questions, ))\n",
        "encoder_embedding = tf.keras.layers.Embedding(VOCAB_SIZE, 200, mask_zero=True)(encoder_inputs)\n",
        "encoder_outputs, state_h, state_c = tf.keras.layers.LSTM(200, return_state=True)(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = tf.keras.layers.Input(shape=(maxlen_answers, ))\n",
        "decoder_embedding = tf.keras.layers.Embedding(VOCAB_SIZE, 200, mask_zero=True)(decoder_inputs)\n",
        "decoder_lstm = tf.keras.layers.LSTM(200, return_state=True, return_sequences=True)\n",
        "decoder_outputs, _ , _  = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "decoder_dense = tf.keras.layers.Dense(VOCAB_SIZE, activation=tf.keras.activations.softmax)\n",
        "output = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output)\n",
        "model.compile(optimizer='adam', loss= tf.keras.losses.categorical_crossentropy, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "JzxkC4EGqWv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l16Z_OUt_iG",
        "outputId": "0f52ae78-4817-4c0c-ccce-372951fcc0d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 9)]          0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 87)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 9, 200)       16200       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 87, 200)      16200       ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 200),        320800      ['embedding[0][0]']              \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 87, 200),    320800      ['embedding_1[0][0]',            \n",
            "                                 (None, 200),                     'lstm[0][1]',                   \n",
            "                                 (None, 200)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 87, 81)       16281       ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 690,281\n",
            "Trainable params: 690,281\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=32, epochs=100)"
      ],
      "metadata": {
        "id": "8qCp44nYuJrw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b54302c0-0858-43c9-e23e-654acd35907e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 8s 8s/step - loss: 2.0202 - accuracy: 0.0083\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 2.0158 - accuracy: 0.1333\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 2.0112 - accuracy: 0.1583\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 2.0062 - accuracy: 0.1500\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 2.0005 - accuracy: 0.1667\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 1.9935 - accuracy: 0.1583\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.9844 - accuracy: 0.1417\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 1.9711 - accuracy: 0.1333\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 1.9496 - accuracy: 0.1167\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 1.9268 - accuracy: 0.1000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.9033 - accuracy: 0.0917\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 1.8802 - accuracy: 0.0750\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.8602 - accuracy: 0.0750\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 1.8381 - accuracy: 0.1167\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.8117 - accuracy: 0.1083\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 1.7806 - accuracy: 0.1000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 1.7423 - accuracy: 0.1000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 1.7244 - accuracy: 0.0833\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 1.6887 - accuracy: 0.1083\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 1.6511 - accuracy: 0.1000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 1.6171 - accuracy: 0.1167\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 1.5902 - accuracy: 0.1083\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.5599 - accuracy: 0.1167\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.5404 - accuracy: 0.1000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 1.5117 - accuracy: 0.1000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.4882 - accuracy: 0.1167\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 1.4604 - accuracy: 0.1250\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 1.4368 - accuracy: 0.1167\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 1.4113 - accuracy: 0.1333\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 1.3879 - accuracy: 0.1333\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 1.3628 - accuracy: 0.1500\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 1.3425 - accuracy: 0.1667\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.3198 - accuracy: 0.1583\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 1.2998 - accuracy: 0.1833\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 1.2787 - accuracy: 0.1667\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 1.2567 - accuracy: 0.1833\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 1.2355 - accuracy: 0.1750\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 1.2180 - accuracy: 0.2000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 1.2121 - accuracy: 0.1833\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 1.2026 - accuracy: 0.1917\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 1.1626 - accuracy: 0.2333\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 1.1543 - accuracy: 0.2500\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 1.1418 - accuracy: 0.2500\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 1.1130 - accuracy: 0.2917\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 1.1111 - accuracy: 0.2667\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 1.0832 - accuracy: 0.2833\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 1.0725 - accuracy: 0.3000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 1.0603 - accuracy: 0.3333\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 1.0353 - accuracy: 0.3667\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 1.0308 - accuracy: 0.3250\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 1.0104 - accuracy: 0.3500\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.9945 - accuracy: 0.4083\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.9870 - accuracy: 0.3917\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.9643 - accuracy: 0.4333\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.9537 - accuracy: 0.4333\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.9432 - accuracy: 0.4167\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.9223 - accuracy: 0.4917\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.9131 - accuracy: 0.4750\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.9044 - accuracy: 0.4500\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.8845 - accuracy: 0.5000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.8720 - accuracy: 0.5333\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.8652 - accuracy: 0.4917\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.8499 - accuracy: 0.5583\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.8339 - accuracy: 0.5750\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.8247 - accuracy: 0.6167\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.8159 - accuracy: 0.6000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.8020 - accuracy: 0.6333\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.7878 - accuracy: 0.6667\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.7777 - accuracy: 0.6667\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.7699 - accuracy: 0.6667\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.7607 - accuracy: 0.6667\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.7478 - accuracy: 0.6833\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.7344 - accuracy: 0.7333\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.7235 - accuracy: 0.7667\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.7150 - accuracy: 0.7917\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.7073 - accuracy: 0.8250\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.6986 - accuracy: 0.7917\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.6881 - accuracy: 0.8417\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.6758 - accuracy: 0.8750\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.6640 - accuracy: 0.8917\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.6537 - accuracy: 0.8917\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.6449 - accuracy: 0.9167\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.6370 - accuracy: 0.9083\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.6292 - accuracy: 0.9083\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.6211 - accuracy: 0.9167\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.6109 - accuracy: 0.9250\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.5995 - accuracy: 0.9417\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.5882 - accuracy: 0.9500\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.5788 - accuracy: 0.9500\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.5710 - accuracy: 0.9500\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.5634 - accuracy: 0.9500\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.5548 - accuracy: 0.9583\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.5445 - accuracy: 0.9583\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.5339 - accuracy: 0.9583\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.5245 - accuracy: 0.9583\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.5164 - accuracy: 0.9667\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.5085 - accuracy: 0.9583\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.4998 - accuracy: 0.9583\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.4901 - accuracy: 0.9667\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.4804 - accuracy: 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Making inferences\n",
        "\n",
        "#For making inferences, two inference models namely the encoder and the decoder inference model are built. \n",
        "# These models undergo similar preprocessing steps as the model did during the training phase.\n",
        "\n",
        "def inference():\n",
        "  encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "  decoder_state_input_h = tf.keras.layers.Input(shape=(200 ,))\n",
        "  decoder_state_input_c = tf.keras.layers.Input(shape=(200 ,))\n",
        "    \n",
        "  decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "    \n",
        "  decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "  decoder_embedding , initial_state=decoder_states_inputs)\n",
        "  decoder_states = [state_h, state_c]\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "  decoder_model = tf.keras.models.Model(\n",
        "      [decoder_inputs] + decoder_states_inputs,\n",
        "      [decoder_outputs] + decoder_states)\n",
        "    \n",
        "  return encoder_model , decoder_model"
      ],
      "metadata": {
        "id": "doRqooQ815Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_input(input_sentence):\n",
        "    tokens = input_sentence.lower().split()\n",
        "    tokens_list = []\n",
        "    for word in tokens:\n",
        "        tokens_list.append(tokenizer.word_index[word]) \n",
        "    return preprocessing.sequence.pad_sequences([tokens_list] , maxlen=maxlen_questions , padding='post')"
      ],
      "metadata": {
        "id": "U9i0EQh72fz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_model , dec_model = inference()"
      ],
      "metadata": {
        "id": "1YBNAqaO2hJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tests = ['How long is the duration of the course', 'What are the entry requirements for the course', 'How much is the tuition fees for the course']\n",
        "\n",
        "for i in range(3):\n",
        "    states_values = enc_model.predict(preprocess_input(tests[i]))\n",
        "    empty_target_seq = np.zeros((1 , 1))\n",
        "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
        "    stop_condition = False\n",
        "    decoded_translation = ''\n",
        "    \n",
        "    while not stop_condition :\n",
        "        dec_outputs , h , c = dec_model.predict([empty_target_seq] + states_values)\n",
        "        sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
        "        sampled_word = None\n",
        "        \n",
        "        for word , index in tokenizer.word_index.items() :\n",
        "            if sampled_word_index == index :\n",
        "                decoded_translation += f' {word}'\n",
        "                sampled_word = word\n",
        "        \n",
        "        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
        "            stop_condition = True\n",
        "            \n",
        "        empty_target_seq = np.zeros((1 , 1))  \n",
        "        empty_target_seq[0 , 0] = sampled_word_index\n",
        "        states_values = [h , c] \n",
        "    print(f'Human: {tests[i]}')\n",
        "    print()\n",
        "    decoded_translation = decoded_translation.split(' end')[0]\n",
        "    print(f'Bot: {decoded_translation}')\n",
        "    print('-'*25)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMyah40_2kTd",
        "outputId": "0f8ff885-2e99-4408-d967-57e1a44dda16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 87) for input KerasTensor(type_spec=TensorSpec(shape=(None, 87), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n",
            "Human: How long is the duration of the course\n",
            "\n",
            "Bot:  three years\n",
            "-------------------------\n",
            "Human: What are the entry requirements for the course\n",
            "\n",
            "Bot:  minimum entry requirements are a grade h5 and above in two higher level subjects together with a minimum of o6 h7 in four other subjects a minimum of grade o6 h7 must be obtained in a grade o5 o5 h6 must be obtained in mathematics for applicants whose first language is not english please note the english language entry requirements mature applicants applicants with a disability or those applying through the dare or hear access schemes can find out more information on the application process\n",
            "-------------------------\n",
            "Human: How much is the tuition fees for the course\n",
            "\n",
            "Bot:  the fees for this course for international students is €10000 per year for domestic students applying through the cao this course applies under the free fees initiative\n",
            "-------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code snippet sources: Kaggle and Stack Overflow"
      ],
      "metadata": {
        "id": "EucMPWl-QD99"
      }
    }
  ]
}